{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Meetup event data\n",
    "\n",
    "## Tasks:\n",
    "1. Imports and preliminaries\n",
    "2. Load group ids\n",
    "3. Data crawl\n",
    " * Extract relevant events\n",
    " * Extract relevant RSVPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import datetime\n",
    "import ratelim\n",
    "import os\n",
    "\n",
    "#Import gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "\n",
    "#Import Matt Williams' script (adapted to Python 3)\n",
    "#import tools_mu\n",
    "#import crawl_group_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#File paths\n",
    "#Path to data files\n",
    "data_path = os.getcwd() + \"/\" + \"meetup_data\"\n",
    "\n",
    "#Read api key from config file 'my_api_key'\n",
    "with open(\"my_api_key.json\",'r') as data_file:\n",
    "    my_api_key = json.load(data_file)['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load group ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract json data.\n",
    "\n",
    "#Observations: json loads works with strings so we had to decode the lines.\n",
    "tech_groups = [json.loads(line.decode()) for line in open(data_path + \"/\" + \"tech_groups.json\",\"rb\")]\n",
    "\n",
    "#Subset groups in Cardiff - we'll work with these, and a random set.\n",
    "cardiff_group_ids = [g['id'] for g in tech_groups if g['city']==\"Cardiff\"]\n",
    "\n",
    "#Extract random sample of 200 groups\n",
    "#Extract 200 random indices based on the tech_groups list\n",
    "random_groups = random.sample(range(0,len(tech_groups)),200)\n",
    "\n",
    "#Get the ids for those\n",
    "random_group_ids = [g['id'] for num,g in enumerate(tech_groups) if num in random_groups]\n",
    "\n",
    "#Final ids (use set to remove duplicates)\n",
    "selected_groups_ids = set(cardiff_group_ids + random_group_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Meetup API url\n",
    "api_base_url = \"https://api.meetup.com/2/\"\n",
    "\n",
    "#Rate limits\n",
    "RATELIM_DUR = 60 * 60\n",
    "RATELIM_QUERIES = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write event crawler\n",
    "@ratelim.patient(RATELIM_QUERIES,RATELIM_DUR)\n",
    "def crawl_events(group_id):\n",
    "    '''\n",
    "    Input: a meetup group id\n",
    "    Output: a json object with information about the group from Meetup\n",
    "    '''\n",
    "    \n",
    "    #Build request\n",
    "    api_url = api_base_url + 'events'\n",
    "    request_parameters = \"?group_id={}&status=past&key={}\".format(group_id,my_api_key)\n",
    "    \n",
    "    event_request = api_url + request_parameters\n",
    "    \n",
    "    #Make API call and obtain response using the get method in requests.\n",
    "    response = requests.get(event_request)\n",
    "    \n",
    "    return(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract events\n",
    "%timeit\n",
    "\n",
    "#This is a list of dicts, each of which has a group and its attendees\n",
    "selected_events = [crawl_events(gid)['results'] for gid in selected_groups_ids]\n",
    "\n",
    "#Extract event ids\n",
    "selected_event_ids = [event['id'] for all_events in selected_events for event in all_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write RSVP crawler\n",
    "@ratelim.patient(RATELIM_QUERIES,RATELIM_DUR)\n",
    "def crawl_rspvs(event_id):\n",
    "    '''\n",
    "    Input: event_id\n",
    "    Output: a json object with information about attendees\n",
    "    '''\n",
    "    \n",
    "    #Build request:\n",
    "    api_url = api_base_url + \"rsvps\"\n",
    "    request_parameters = \"?&event_id={}&key={}\".format(event_id,my_api_key)\n",
    "    \n",
    "    rsvps_request = api_url + request_parameters\n",
    "    \n",
    "    #Make request\n",
    "    response = requests.get(rsvps_request)\n",
    "    \n",
    "    return(response.json())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 25 µs\n"
     ]
    }
   ],
   "source": [
    "#Extract rsvps for each group/event.\n",
    "#Want to end with a list where every element is a group with events and rsvps\n",
    "#%time\n",
    "\n",
    "#selected_rsvps = [crawl_rspvs('results') for eid in selected_event_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory analysis\n",
    "### a. Event description\n",
    "\n",
    "#### Tasks\n",
    "* Extract topic descriptions, dates and groups.\n",
    "* Preliminary analysis of descriptions\n",
    "* Preprocessing (lemmatize, stem, tokenize)\n",
    "* Model and measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create function that extracts an element from a dict only if that key exists\n",
    "def extract_element(dictionary,key):\n",
    "    '''\n",
    "    Input: a dictionary and a key.\n",
    "    Output: The value of the key if it exists; \"NA\" if not.\n",
    "    '''\n",
    "    try:\n",
    "        out = dictionary[key]\n",
    "    except:\n",
    "        out = \"No Key\"\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract event descriptions\n",
    "event_desc = [extract_element(event,\"description\") for group in selected_events for event in group]\n",
    "\n",
    "#Also extract group cities. We will remove them later from text descriptions\n",
    "group_cities = set([g['city'].lower() for g in tech_groups if g['id'] in selected_groups_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load stop words.\n",
    "stop_words = stopwords.words('english')\n",
    "english_words = words.words()\n",
    "#Load lemmatizer to lemmatize words\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "#Create list of words to remove\n",
    "words_to_remove = list(set(stop_words+list(group_cities)+english_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_html(raw_html):\n",
    "    cleanr =re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr,'', raw_html)\n",
    "    return(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process_text(document):\n",
    "    '''\n",
    "    input = document, a string\n",
    "    output = A list of tokens for analysis in gensim\n",
    "    '''\n",
    "    \n",
    "    #To lowercase\n",
    "    doc_low = document.lower()\n",
    "    \n",
    "    #Remove html\n",
    "    s_no_html = re.sub('<[^<]+?>', '', doc_low)\n",
    "    \n",
    "    #Remove punctuation\n",
    "    s_no_punct = \"\".join([w for w in s_no_html if w not in string.punctuation])\n",
    "    \n",
    "    \n",
    "    #Tokenize and lemmatize\n",
    "    tokens = nltk.word_tokenize(s_no_punct)\n",
    "    tokens_lemmatized = [lmtzr.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    \n",
    "    #Get position\n",
    "    tokens_lab = nltk.pos_tag(tokens_lemmatized)\n",
    "    \n",
    "    #Focus on nouns and remove stopwords\n",
    "    tokens_selected = [tok[0] for tok in tokens_lab if tok[1]==\"NN\" and \n",
    "                      tok[0] not in words_to_remove]\n",
    "    \n",
    "    return(tokens_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Process all text\n",
    "event_description_corpus = [pre_process_text(doc) for doc in event_desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a dictionary of unique tokens\n",
    "dictionary = corpora.Dictionary(event_description_corpus)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in event_description_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_idf = models.TfidfModel(corpus)\n",
    "tf_idf_corpus = tf_idf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel(tf_idf_corpus, id2word=dictionary, num_topics=20,passes=10,iterations=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13,\n",
       "  '0.024*youre + 0.023*django + 0.021*brian + 0.020*conversocial + 0.018*castletypething + 0.013*gareth + 0.013*startup + 0.007*bdd + 0.006*qampa + 0.005*dennisdropin'),\n",
       " (14,\n",
       "  '0.026*eresearch + 0.024*centre + 0.019*meetup + 0.019*wednesday + 0.010*tbc + 0.006*lineup + 0.005*october + 0.005*crowdsource + 0.005*gettogether + 0.005*rsvp'),\n",
       " (7,\n",
       "  '0.044*benugo + 0.015*organiser + 0.015*amp + 0.014*cheerspaul + 0.014*gitter + 0.007*meetup + 0.005*techie + 0.005*sophie + 0.005*networking + 0.004*•'),\n",
       " (9,\n",
       "  '0.075*xpday + 0.009*php + 0.007*janice + 0.006*feb + 0.006*harvey + 0.005*max + 0.005*dropin + 0.004*bitcoin + 0.004*ed + 0.004*that’s'),\n",
       " (0,\n",
       "  '0.022*startup + 0.016*• + 0.015*app + 0.015*google + 0.013*apps + 0.012*webinar + 0.009*im + 0.009*blogger + 0.008*youll + 0.008*meetup')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alas, this doesn't seem to work\n",
    "lda_model.show_topics(num_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Group keywords\n",
    "#### Tasks\n",
    "* Extract keywords and date created from groups\n",
    "* Option 1: bin keywords by month and perform tf-idf. What are the top keywords per month?\n",
    "* Option 2: topic model all keywords with large n and explore topic distribution per month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_topics_from_dict(topic,container):\n",
    "    '''\n",
    "    input: a container (list) of dictionaries and a key (topic) to extract\n",
    "    output: a list with the topics\n",
    "    '''\n",
    "    \n",
    "    out = [top[topic] for top in container]\n",
    "    return(out)\n",
    "\n",
    "def extract_date_from_epoch(posix_date):\n",
    "    '''\n",
    "    input: a POSIX timestamp.\n",
    "    output: a local date\n",
    "    '''\n",
    "    out = datetime.datetime.fromtimestamp(posix_date).strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract keywords and dates created from groups\n",
    "\n",
    "group_topics = [{\"group_id\": g[\"_id\"],\n",
    "                 \"group_created\": extract_date_from_epoch(\n",
    "            int(g[\"created\"]['$numberLong'])/1000),\n",
    "                   \"group_topics\":extract_topics_from_dict('urlkey',g['topics'])} for\n",
    "                g in tech_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Binning\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group_created': '03-01-2006',\n",
       " 'group_id': 218194,\n",
       " 'group_topics': ['php',\n",
       "  'opensource',\n",
       "  'softwaredev',\n",
       "  'edtech',\n",
       "  'newtech',\n",
       "  'ria',\n",
       "  'internetpro',\n",
       "  'lampsoftware',\n",
       "  'web',\n",
       "  'drupal',\n",
       "  'technology',\n",
       "  'web-development',\n",
       "  'cms',\n",
       "  'computer-programming']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_topics[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create dataframe and use groupby\n",
    "group_topics_df = pd.DataFrame(group_topics)\n",
    "\n",
    "#Create a month bin where day is always one\n",
    "group_topics_df['created_date'] = group_topics_df[\n",
    "    'group_created'].apply(lambda x:\n",
    "                           datetime.datetime.strptime(\"01-\" + x[3:],\"%d-%m-%Y\"))    \n",
    "\n",
    "#Bin over created_date\n",
    "topics_by_month = group_topics_df.groupby('created_date')['group_topics'].apply(lambda x:\n",
    "                                                               [t for group in x for t in group])\n",
    "\n",
    "#Remove keywords that only appear one\n",
    "def remove_vrare_keywords(keyword_list,threshold=1):\n",
    "    '''\n",
    "    input: list of keywords and a threshold for inclusion\n",
    "    output: counts the number of keyword occurrences in the period and removes\n",
    "        #those that appear below the threshold\n",
    "    '''\n",
    "    topic_subset = [topic for topic in keyword_list if keyword_list.count(topic)>threshold]\n",
    "    return(topic_subset)\n",
    "\n",
    "topics_by_month = topics_by_month.apply(remove_vrare_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Next steps:\n",
    "#Create a corpus where periods are documents, and transform via tf idf.\n",
    "\n",
    "#Create the dictionary.\n",
    "month_keyword_dictionary = corpora.Dictionary(topics_by_month)\n",
    "\n",
    "#Create the bag of words\n",
    "month_keyword_bow = [month_keyword_dictionary.doc2bow(doc) for doc in topics_by_month]\n",
    "\n",
    "#Apply tf-idf transformation\n",
    "#Initialise model to learn term document frequencies\n",
    "month_keyword_tfidf = models.TfidfModel(month_keyword_bow)\n",
    "month_kword_tfidf_fit = month_keyword_tfidf[month_keyword_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Map token ids to keywords and extract top 5 per month.\n",
    "\n",
    "#This dictionary maps token names to id integers\n",
    "token_ids = month_keyword_dictionary.token2id\n",
    "\n",
    "\n",
    "#Lookup function between token ids and tokens\n",
    "def obtain_token_from_id(token_id):\n",
    "    '''\n",
    "    input: an id for a token\n",
    "    output\" the token (group keyword)\n",
    "    '''\n",
    "    \n",
    "    #Converts the token ids keys into a list selected by the index of the token_id in\n",
    "        #the values list\n",
    "    my_token = list(token_ids.keys())[list(token_ids.values()).index(token_id)]\n",
    "    return(my_token)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to extract top topics by month\n",
    "\n",
    "def obtain_top_tokens_by_month(month_values,threshold=5):\n",
    "    '''\n",
    "    input: the tf-idf values for tokens in one month\n",
    "    returns: the top 10 tokens\n",
    "    \n",
    "    '''\n",
    "    #Create dataframe for sorting easily\n",
    "    df = pd.DataFrame(month_values,columns=['id','weight'])\n",
    "    df.sort(columns=\"weight\",inplace=True,ascending=False)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #Extract tokens\n",
    "    df['topic'] = df['id'].apply(lambda x: obtain_token_from_id(x))\n",
    "    \n",
    "    if len(df)-1<threshold:\n",
    "        return(\", \".join(list(df.ix[:len(df)-1,'topic'])))\n",
    "    else:\n",
    "        return(\", \".join(list(df.ix[:threshold-1,'topic'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "top_tokens_monthly = [\n",
    "    {\"month\":topics_by_month.index[i],\n",
    "     \"top_topics\":obtain_top_tokens_by_month(j)}\n",
    "    for i,j in enumerate(list(month_kword_tfidf_fit))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>top_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-10-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-10-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-06-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-07-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-11-01</td>\n",
       "      <td>computer-programming, softwaredev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008-03-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008-04-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2008-06-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2008-07-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2008-08-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2008-09-01</td>\n",
       "      <td>technology-startups, entrepreneurship, webdesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>professional-networking, technology, internetp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008-11-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2009-02-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2009-03-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2009-04-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2009-05-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2009-07-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2009-08-01</td>\n",
       "      <td>webstandards, php, it-professionals, ruby, cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2009-09-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2009-10-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2009-11-01</td>\n",
       "      <td>internetpro, web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2009-12-01</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>jquery, mysql, css, physical-computing, apps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>storytelling, embedded-systems, ruby-on-rails,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>software-craftsmanship, computer-programming, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>mysql, 3d-artists, wordpress-for-business, wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>digitalrights, software-product-management, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>web-operations, iaas-infrastructure-as-a-servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>android-app-marketing, finance, mobile-game-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>web-application, opensource, makers, apis, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>software-architecture, software-engineering, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>civic-engagement-technology, android-developer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>information-technology-in-business, diy-techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>software-quality, agile-leadership, edtech, ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>open-source-frameworks, javascript-libraries, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>css, html-and-css, programming-languages, it-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>kx, testing-tools, data-science, big-data, tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>newtech, asp-net, cryptography, softwaredev, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>newtech, computer-programming, business-strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>newtech, drupal, agile-testing, agile-mindset,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>aws-design-implementation-and-servicing, ec2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>marketing, sql, databasepro, computer-programm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>ai, linux, machine-learning, agile-testing, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>newtech, android, android-developers, technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>internet-ecommerce, vr-glasses, python-linux-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>learn-coding, coders, product-management, soft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>application-security, newtech, lean-project-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>softwaredev, machine-intelligence, open-source...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>video-game-development, information-security, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>ui-design, computer-programming, coders, softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>professional-networking, prodev, softwaredev, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>edtech, newtech, smart-home, cms, softwaredev</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         month                                         top_topics\n",
       "0   2002-10-01                                                   \n",
       "1   2006-01-01                                                   \n",
       "2   2006-04-01                                                   \n",
       "3   2006-10-01                                                   \n",
       "4   2007-01-01                                                   \n",
       "5   2007-02-01                                                   \n",
       "6   2007-06-01                                                   \n",
       "7   2007-07-01                                                   \n",
       "8   2007-11-01                  computer-programming, softwaredev\n",
       "9   2008-01-01                                                   \n",
       "10  2008-03-01                                                   \n",
       "11  2008-04-01                                                   \n",
       "12  2008-06-01                                                   \n",
       "13  2008-07-01                                                   \n",
       "14  2008-08-01                                                   \n",
       "15  2008-09-01  technology-startups, entrepreneurship, webdesi...\n",
       "16  2008-10-01  professional-networking, technology, internetp...\n",
       "17  2008-11-01                                                   \n",
       "18  2008-12-01                                                   \n",
       "19  2009-01-01                                                   \n",
       "20  2009-02-01                                                   \n",
       "21  2009-03-01                                                   \n",
       "22  2009-04-01                                                   \n",
       "23  2009-05-01                                                   \n",
       "24  2009-07-01                                                   \n",
       "25  2009-08-01     webstandards, php, it-professionals, ruby, cms\n",
       "26  2009-09-01                                                   \n",
       "27  2009-10-01                                                   \n",
       "28  2009-11-01                                   internetpro, web\n",
       "29  2009-12-01                                                   \n",
       "..         ...                                                ...\n",
       "75  2013-10-01       jquery, mysql, css, physical-computing, apps\n",
       "76  2013-11-01  storytelling, embedded-systems, ruby-on-rails,...\n",
       "77  2013-12-01  software-craftsmanship, computer-programming, ...\n",
       "78  2014-01-01  mysql, 3d-artists, wordpress-for-business, wor...\n",
       "79  2014-02-01  digitalrights, software-product-management, in...\n",
       "80  2014-03-01  web-operations, iaas-infrastructure-as-a-servi...\n",
       "81  2014-04-01  android-app-marketing, finance, mobile-game-de...\n",
       "82  2014-05-01  web-application, opensource, makers, apis, mak...\n",
       "83  2014-06-01  software-architecture, software-engineering, s...\n",
       "84  2014-07-01  civic-engagement-technology, android-developer...\n",
       "85  2014-08-01  information-technology-in-business, diy-techno...\n",
       "86  2014-09-01  software-quality, agile-leadership, edtech, ag...\n",
       "87  2014-10-01  open-source-frameworks, javascript-libraries, ...\n",
       "88  2014-11-01  css, html-and-css, programming-languages, it-p...\n",
       "89  2014-12-01  kx, testing-tools, data-science, big-data, tes...\n",
       "90  2015-01-01  newtech, asp-net, cryptography, softwaredev, d...\n",
       "91  2015-02-01  newtech, computer-programming, business-strate...\n",
       "92  2015-03-01  newtech, drupal, agile-testing, agile-mindset,...\n",
       "93  2015-04-01  aws-design-implementation-and-servicing, ec2, ...\n",
       "94  2015-05-01  marketing, sql, databasepro, computer-programm...\n",
       "95  2015-06-01  ai, linux, machine-learning, agile-testing, so...\n",
       "96  2015-07-01  newtech, android, android-developers, technolo...\n",
       "97  2015-08-01  internet-ecommerce, vr-glasses, python-linux-d...\n",
       "98  2015-09-01  learn-coding, coders, product-management, soft...\n",
       "99  2015-10-01  application-security, newtech, lean-project-ma...\n",
       "100 2015-11-01  softwaredev, machine-intelligence, open-source...\n",
       "101 2015-12-01  video-game-development, information-security, ...\n",
       "102 2016-01-01  ui-design, computer-programming, coders, softw...\n",
       "103 2016-02-01  professional-networking, prodev, softwaredev, ...\n",
       "104 2016-03-01      edtech, newtech, smart-home, cms, softwaredev\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Still not super-informative\n",
    "pd.DataFrame(top_tokens_monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Option 2: LDA with all keywords.\n",
    "#Create list of documents with keywords\n",
    "group_topics_list = [g['group_topics'] for g in group_topics]\n",
    "\n",
    "#Create dictionary.\n",
    "gr_keyword_dictionary = corpora.Dictionary(group_topics_list)\n",
    "\n",
    "#Create bag of words representation\n",
    "gr_keyword_corpus = [gr_keyword_dictionary.doc2bow(gr) for gr in group_topics_list]\n",
    "\n",
    "#Initialise tf-idf model\n",
    "gr_keyword_tfidf = models.TfidfModel(gr_keyword_corpus)\n",
    "\n",
    "#Fit tf-idf model\n",
    "gr_tfidf_corpus = gr_keyword_tfidf[gr_keyword_corpus]\n",
    "\n",
    "#Initialise lda model\n",
    "gr_keyword_lda = models.LdaModel(gr_tfidf_corpus,\n",
    "                                id2word=gr_keyword_dictionary,num_topics=100,\n",
    "                                passes=20,iterations=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(86,\n",
       "  '0.091*makers + 0.090*arduino + 0.088*makerspaces + 0.078*electronics + 0.058*robotics + 0.057*3d-printing + 0.055*hacking + 0.039*diy + 0.016*newtech + 0.015*computer-programming'),\n",
       " (84,\n",
       "  '0.024*bioinformatics + 0.023*creative-problem-solving + 0.020*genomics + 0.019*human-centered-design + 0.019*it-infrastructure + 0.019*creative-thinking + 0.016*computational-biology + 0.016*rapid-prototyping + 0.013*web-content-management + 0.013*sitecore'),\n",
       " (27,\n",
       "  '0.036*angel-investors + 0.032*apache-lucene-and-solr-open-source-search + 0.028*elasticsearch + 0.028*enterprise-search + 0.027*software-development-technologies + 0.025*text-analytics + 0.019*lucene-solr-nutch-mahout-and-open-source-search + 0.018*search-engines + 0.016*search-information-retrieval + 0.015*natural-language-processing'),\n",
       " (57,\n",
       "  '0.028*drupal-7 + 0.025*quantitative-analysis + 0.024*quants + 0.018*scandinavian + 0.016*algorithmic-trading + 0.016*inventors-and-product-developers + 0.015*communityorg + 0.014*apache-hive + 0.014*digital-media + 0.012*quantitative-finance'),\n",
       " (20,\n",
       "  '0.019*digital-access + 0.018*front-end-engineering + 0.015*duckduckgo + 0.014*journalism + 0.013*music-technology + 0.013*perl + 0.012*christian-entrepreneurs + 0.012*faith + 0.010*gis + 0.009*strategy')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_keyword_lda.show_topics(num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create doc topic distribution with the bow corpus\n",
    "doc_topics = gr_keyword_lda[gr_tfidf_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a df with the topic distributions per group\n",
    "group_topdist = pd.DataFrame([dict(tup) for tup in list(doc_topics)]).fillna(value=0)\n",
    "\n",
    "#Concatenate with the month when the group was created, groupby and aggregate.\n",
    "group_topdist_df = pd.concat([group_topdist,group_topics_df['created_date']],axis=1)\n",
    "\n",
    "#Create month distributions by grouping and aggregating\n",
    "month_dist_df = group_topdist_df.groupby(\"created_date\").sum()\n",
    "\n",
    "#Plot this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
